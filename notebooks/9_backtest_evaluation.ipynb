{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Model Backtesting & Historical Evaluation\n",
    "\n",
    "Evaluate model performance on historical data to understand prediction quality.\n",
    "\n",
    "**Purpose**: Backtest evaluation (evaluate past predictions)\n",
    "**Data Source**: Historical data from `qqq_combined_features` with known targets\n",
    "**Output**: Performance metrics and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from utils.hopsworks_helpers import get_feature_store\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "regressor = joblib.load('../models/qqq_regressor.pkl')\n",
    "classifier = joblib.load('../models/qqq_classifier.pkl')\n",
    "\n",
    "print(\"✓ Models loaded\")\n",
    "print(f\"  Features expected: {regressor.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Hopsworks and load data\n",
    "fs = get_feature_store()\n",
    "combined_fg = fs.get_feature_group('qqq_combined_features', version=1)\n",
    "df = combined_fg.read()\n",
    "\n",
    "# Sort by date\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "if hasattr(df['date'].dtype, 'tz') and df['date'].dtype.tz is not None:\n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Data loaded: {len(df)} rows\")\n",
    "print(f\"  Date range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Evaluation Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select last N days for evaluation\n",
    "EVAL_DAYS = 60  # Evaluate last 60 trading days\n",
    "\n",
    "eval_df = df.tail(EVAL_DAYS).copy()\n",
    "\n",
    "print(f\"\\n=== EVALUATION PERIOD ===\")\n",
    "print(f\"Evaluating last {EVAL_DAYS} trading days\")\n",
    "print(f\"Date range: {eval_df['date'].min()} to {eval_df['date'].max()}\")\n",
    "print(f\"Total samples: {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features (Same as Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "feature_cols = [col for col in eval_df.columns \n",
    "                if col not in ['date', 'qqq_close', 'target_return', 'target_direction']]\n",
    "\n",
    "X_eval = eval_df[feature_cols].copy()\n",
    "\n",
    "# Drop same features as in training\n",
    "cols_to_drop = ['sentiment_mean', 'sentiment_std', 'article_count']\n",
    "X_eval = X_eval.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Get targets\n",
    "y_eval_return = eval_df['target_return']\n",
    "y_eval_direction = eval_df['target_direction']\n",
    "\n",
    "print(f\"\\n✓ Features prepared\")\n",
    "print(f\"  Feature count: {X_eval.shape[1]}\")\n",
    "print(f\"  Samples: {X_eval.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred_returns = regressor.predict(X_eval)\n",
    "pred_directions = classifier.predict(X_eval)\n",
    "pred_probas = classifier.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Regression metrics\n",
    "mae = mean_absolute_error(y_eval_return, pred_returns)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval_return, pred_returns))\n",
    "r2 = r2_score(y_eval_return, pred_returns)\n",
    "\n",
    "# Directional accuracy from regression\n",
    "directional_acc_reg = accuracy_score(\n",
    "    (y_eval_return > 0).astype(int),\n",
    "    (pred_returns > 0).astype(int)\n",
    ")\n",
    "\n",
    "# Classification metrics\n",
    "clf_accuracy = accuracy_score(y_eval_direction, pred_directions)\n",
    "auc = roc_auc_score(y_eval_direction, pred_probas)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PERFORMANCE METRICS (Last {EVAL_DAYS} Days)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nREGRESSION MODEL:\")\n",
    "print(f\"  MAE:  {mae:.6f}\")\n",
    "print(f\"  RMSE: {rmse:.6f}\")\n",
    "print(f\"  R²:   {r2:.6f}\")\n",
    "print(f\"  Directional Accuracy: {directional_acc_reg:.4f} ({directional_acc_reg*100:.2f}%)\")\n",
    "print(f\"\\nCLASSIFICATION MODEL:\")\n",
    "print(f\"  Accuracy: {clf_accuracy:.4f} ({clf_accuracy*100:.2f}%)\")\n",
    "print(f\"  AUC-ROC:  {auc:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Predicted vs Actual Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Time series of returns\n",
    "ax = axes[0]\n",
    "dates = eval_df['date'].values\n",
    "ax.plot(dates, y_eval_return.values, label='Actual Return', marker='o', alpha=0.7, linewidth=2)\n",
    "ax.plot(dates, pred_returns, label='Predicted Return', marker='x', alpha=0.7, linewidth=2)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Return')\n",
    "ax.set_title(f'Predicted vs Actual Returns (Last {EVAL_DAYS} Days)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Prediction probabilities\n",
    "ax = axes[1]\n",
    "colors = ['green' if actual == 1 else 'red' for actual in y_eval_direction]\n",
    "ax.bar(dates, pred_probas, color=colors, alpha=0.6, width=0.8)\n",
    "ax.axhline(y=0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Predicted Probability (UP)')\n",
    "ax.set_title('Predicted Probability of UP Movement (Green=Actual UP, Red=Actual DOWN)')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Scatter Plot & Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax = axes[0]\n",
    "ax.scatter(y_eval_return, pred_returns, alpha=0.6, s=50)\n",
    "ax.plot([y_eval_return.min(), y_eval_return.max()], \n",
    "        [y_eval_return.min(), y_eval_return.max()], \n",
    "        'r--', lw=2, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Return')\n",
    "ax.set_ylabel('Predicted Return')\n",
    "ax.set_title('Predicted vs Actual Returns')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals histogram\n",
    "ax = axes[1]\n",
    "residuals = y_eval_return - pred_returns\n",
    "ax.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='r', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Prediction Error (Actual - Predicted)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Residuals Distribution (Mean={residuals.mean():.6f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Strategy Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate simple trading strategy based on predictions\n",
    "strategy_returns = []\n",
    "buy_and_hold_returns = []\n",
    "\n",
    "for i in range(len(eval_df)):\n",
    "    actual_return = y_eval_return.iloc[i]\n",
    "    predicted_direction = pred_directions[i]\n",
    "    \n",
    "    # Strategy: Long if predict UP, flat if predict DOWN\n",
    "    if predicted_direction == 1:  # Predict UP\n",
    "        strategy_returns.append(actual_return)\n",
    "    else:  # Predict DOWN\n",
    "        strategy_returns.append(0)  # Stay out of market\n",
    "    \n",
    "    # Buy and hold\n",
    "    buy_and_hold_returns.append(actual_return)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "strategy_cumulative = np.cumprod(1 + np.array(strategy_returns)) - 1\n",
    "buy_hold_cumulative = np.cumprod(1 + np.array(buy_and_hold_returns)) - 1\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(dates, strategy_cumulative * 100, label='Strategy (Model-Based)', linewidth=2)\n",
    "plt.plot(dates, buy_hold_cumulative * 100, label='Buy & Hold', linewidth=2, alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return (%)')\n",
    "plt.title(f'Strategy Performance vs Buy & Hold (Last {EVAL_DAYS} Days)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== TRADING STRATEGY RESULTS ===\")\n",
    "print(f\"Strategy Cumulative Return: {strategy_cumulative[-1]*100:+.2f}%\")\n",
    "print(f\"Buy & Hold Cumulative Return: {buy_hold_cumulative[-1]*100:+.2f}%\")\n",
    "print(f\"Outperformance: {(strategy_cumulative[-1] - buy_hold_cumulative[-1])*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive backtesting evaluation:\n",
    "- ✅ Historical performance metrics\n",
    "- ✅ Prediction vs actual visualization\n",
    "- ✅ Trading strategy simulation\n",
    "- ✅ Model quality assessment\n",
    "\n",
    "Use this notebook to:\n",
    "- Evaluate model performance over time\n",
    "- Identify when models need retraining\n",
    "- Validate prediction quality before deployment\n",
    "- Compare different model versions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
