{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 6. Create Feature View for Model Training\n",
    "\n",
    "Join all engineered feature groups and create targets for QQQ prediction.\n",
    "\n",
    "**Pipeline**: Hopsworks FGs (engineered) → Feature View with Targets\n",
    "\n",
    "**Key Components**:\n",
    "- **Feature Join**: Time-aligned merge of all feature groups on date\n",
    "- **Target Creation**: Next-day return (regression) and direction (classification)\n",
    "- **Missing Value Handling**: Drop NaN from rolling windows, fill sentiment with 0\n",
    "- **Feature View**: Hopsworks object for training data access\n",
    "\n",
    "**Critical**: Targets use `.shift(-1)` which is safe because we drop the last row (no future data available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from utils.hopsworks_helpers import get_feature_store, create_feature_group\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load config\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks and Load Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Hopsworks\n",
    "print(\"Connecting to Hopsworks...\")\n",
    "fs = get_feature_store()\n",
    "print(f\"✓ Connected to feature store: {fs.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required feature groups\n",
    "print(\"\\nLoading feature groups...\")\n",
    "\n",
    "qqq_tech_fg = fs.get_feature_group('qqq_technical_features', version=1)\n",
    "xlk_sector_fg = fs.get_feature_group('xlk_sector_features', version=1)\n",
    "vix_vol_fg = fs.get_feature_group('vix_volatility_features', version=1)\n",
    "macro_fg = fs.get_feature_group('macro_features', version=1)\n",
    "qqq_raw_fg = fs.get_feature_group('qqq_raw', version=1)\n",
    "\n",
    "print(\"✓ Required feature groups loaded\")\n",
    "\n",
    "# Try to load optional sentiment features\n",
    "has_sentiment = False\n",
    "try:\n",
    "    sentiment_fg = fs.get_feature_group('sentiment_features', version=1)\n",
    "    has_sentiment = True\n",
    "    print(\"✓ Sentiment features loaded (optional)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Sentiment features not found (optional): {e}\")\n",
    "    print(\"  Proceeding without sentiment data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Read and Preview Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all feature groups\n",
    "print(\"\\nReading feature groups...\")\n",
    "\n",
    "qqq_tech = qqq_tech_fg.read()\n",
    "xlk_sector = xlk_sector_fg.read()\n",
    "vix_vol = vix_vol_fg.read()\n",
    "macro = macro_fg.read()\n",
    "qqq_raw = qqq_raw_fg.read()\n",
    "\n",
    "print(f\"✓ QQQ technical features: {qqq_tech.shape}\")\n",
    "print(f\"✓ XLK sector features: {xlk_sector.shape}\")\n",
    "print(f\"✓ VIX volatility features: {vix_vol.shape}\")\n",
    "print(f\"✓ Macro features: {macro.shape}\")\n",
    "print(f\"✓ QQQ raw (for target): {qqq_raw.shape}\")\n",
    "\n",
    "if has_sentiment:\n",
    "    sentiment = sentiment_fg.read()\n",
    "    print(f\"✓ Sentiment features: {sentiment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview feature groups\n",
    "print(\"\\nQQQ Technical Features:\")\n",
    "print(qqq_tech.head())\n",
    "print(f\"\\nColumns: {qqq_tech.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Join All Feature Groups\n",
    "\n",
    "Perform time-aligned left joins on the date column:\n",
    "- Start with QQQ technical features (base)\n",
    "- Left join all other feature groups\n",
    "- Sentiment features filled with 0 if missing (no news that day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Joining feature groups...\")\n",
    "\n",
    "# Start with QQQ technical features as base\n",
    "features = qqq_tech.copy()\n",
    "\n",
    "# Join XLK sector features\n",
    "features = features.merge(xlk_sector, on='date', how='left', suffixes=('', '_xlk'))\n",
    "\n",
    "# Join VIX volatility features\n",
    "features = features.merge(vix_vol, on='date', how='left', suffixes=('', '_vix'))\n",
    "\n",
    "# Join macro features\n",
    "features = features.merge(macro, on='date', how='left', suffixes=('', '_macro'))\n",
    "\n",
    "# Join sentiment features if available\n",
    "if has_sentiment:\n",
    "    features = features.merge(sentiment, on='date', how='left', suffixes=('', '_sent'))\n",
    "\n",
    "# Add raw QQQ close for target calculation\n",
    "features = features.merge(qqq_raw[['date', 'qqq_close']], on='date', how='left')\n",
    "\n",
    "# Sort by date\n",
    "features = features.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n✓ Combined features shape: {features.shape}\")\n",
    "print(f\"  Total columns: {len(features.columns)}\")\n",
    "print(f\"  Date range: {features['date'].min()} to {features['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview combined features\n",
    "print(\"\\nCombined features preview:\")\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Create Target Variables\n",
    "\n",
    "**Target 1**: `target_return` (regression)\n",
    "- Next-day percentage return of QQQ\n",
    "- Calculated as: `(close_t+1 / close_t) - 1`\n",
    "- Uses `.shift(-1)` which is safe because we drop the last row\n",
    "\n",
    "**Target 2**: `target_direction` (classification)\n",
    "- Binary: 1 if next-day return > 0, else 0\n",
    "- For up/down prediction\n",
    "\n",
    "**Important**: The last row will have NaN targets (no future data), so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating target variables...\")\n",
    "\n",
    "# Target 1: Next-day return (regression)\n",
    "# shift(-1) gets tomorrow's close, then calculate return\n",
    "features['next_day_close'] = features['qqq_close'].shift(-1)\n",
    "features['target_return'] = (features['next_day_close'] / features['qqq_close']) - 1\n",
    "\n",
    "# Target 2: Binary up/down (classification)\n",
    "features['target_direction'] = (features['target_return'] > 0).astype(int)\n",
    "\n",
    "# Drop temporary column\n",
    "features = features.drop(columns=['next_day_close'])\n",
    "\n",
    "print(f\"\\n✓ Targets created\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(features['target_return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target distribution\n",
    "print(\"\\nTarget distribution (classification):\")\n",
    "print(features['target_direction'].value_counts())\n",
    "print(f\"\\nUp days: {(features['target_direction'] == 1).sum()} ({(features['target_direction'] == 1).mean()*100:.1f}%)\")\n",
    "print(f\"Down days: {(features['target_direction'] == 0).sum()} ({(features['target_direction'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Handle Missing Values\n",
    "\n",
    "Missing values come from:\n",
    "1. **Rolling windows**: First N rows have NaN for N-day features\n",
    "2. **Sentiment**: Some days may have no news articles\n",
    "3. **Target**: Last row has NaN (no future data)\n",
    "\n",
    "Strategy:\n",
    "- Fill sentiment features with 0 (no news = neutral sentiment)\n",
    "- Drop rows with NaN targets\n",
    "- Drop remaining NaN (from rolling windows at start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values before handling\n",
    "print(\"Missing values per column:\")\n",
    "missing = features.isnull().sum()\n",
    "missing_cols = missing[missing > 0].sort_values(ascending=False)\n",
    "print(missing_cols.head(20))\n",
    "print(f\"\\nTotal rows with any missing: {features.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle sentiment features (fill with 0 if no news)\n",
    "if has_sentiment:\n",
    "    sentiment_cols = [col for col in features.columns if 'sentiment' in col.lower() or col in ['article_count', 'positive_mean', 'negative_mean', 'neutral_mean']]\n",
    "    print(f\"\\nFilling {len(sentiment_cols)} sentiment columns with 0 (no news)...\")\n",
    "    for col in sentiment_cols:\n",
    "        features[col] = features[col].fillna(0)\n",
    "    print(\"✓ Sentiment features filled\")\n",
    "\n",
    "# Drop rows with missing targets (last row)\n",
    "features_with_targets = features.dropna(subset=['target_return', 'target_direction'])\n",
    "print(f\"\\n✓ Dropped {len(features) - len(features_with_targets)} rows with missing targets\")\n",
    "\n",
    "# Drop remaining rows with NaN (rolling window initialization)\n",
    "features_clean = features_with_targets.dropna()\n",
    "print(f\"✓ Dropped {len(features_with_targets) - len(features_clean)} rows with NaN from rolling windows\")\n",
    "\n",
    "print(f\"\\nFinal clean dataset shape: {features_clean.shape}\")\n",
    "print(f\"Date range: {features_clean['date'].min()} to {features_clean['date'].max()}\")\n",
    "print(f\"Total training samples: {len(features_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no missing values remain\n",
    "remaining_missing = features_clean.isnull().sum().sum()\n",
    "print(f\"\\nRemaining missing values: {remaining_missing}\")\n",
    "if remaining_missing > 0:\n",
    "    print(\"WARNING: Still have missing values!\")\n",
    "    print(features_clean.isnull().sum()[features_clean.isnull().sum() > 0])\n",
    "else:\n",
    "    print(\"✓ No missing values in clean dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Analyze Feature Correlations with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with target_return\n",
    "feature_cols = [col for col in features_clean.columns \n",
    "                if col not in ['date', 'qqq_close', 'target_return', 'target_direction']]\n",
    "\n",
    "correlations = features_clean[feature_cols].corrwith(features_clean['target_return']).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 features positively correlated with next-day return:\")\n",
    "print(correlations.head(10))\n",
    "print(\"\\nTop 10 features negatively correlated with next-day return:\")\n",
    "print(correlations.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Top positive correlations\n",
    "top_positive = correlations.head(10)\n",
    "ax1.barh(range(len(top_positive)), top_positive.values)\n",
    "ax1.set_yticks(range(len(top_positive)))\n",
    "ax1.set_yticklabels(top_positive.index)\n",
    "ax1.set_xlabel('Correlation with Next-Day Return')\n",
    "ax1.set_title('Top 10 Positive Correlations')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Top negative correlations\n",
    "top_negative = correlations.tail(10).sort_values()\n",
    "ax2.barh(range(len(top_negative)), top_negative.values)\n",
    "ax2.set_yticks(range(len(top_negative)))\n",
    "ax2.set_yticklabels(top_negative.index)\n",
    "ax2.set_xlabel('Correlation with Next-Day Return')\n",
    "ax2.set_title('Top 10 Negative Correlations')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Feature correlations analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Upload Combined Feature Group to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined feature group with all features and targets\n",
    "print(\"\\nUploading combined feature group to Hopsworks...\")\n",
    "\n",
    "combined_fg = create_feature_group(\n",
    "    fs,\n",
    "    name='qqq_combined_features',\n",
    "    df=features_clean,\n",
    "    primary_key=['date'],\n",
    "    description='Combined feature set with all engineered features and prediction targets (next-day return and direction)'\n",
    ")\n",
    "\n",
    "print(f\"✓ Created feature group: qqq_combined_features (version {combined_fg.version})\")\n",
    "print(f\"  Total features: {len(feature_cols)}\")\n",
    "print(f\"  Total samples: {len(features_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Create Feature View for Model Training\n",
    "\n",
    "A Feature View in Hopsworks:\n",
    "- Defines which features to use for training\n",
    "- Specifies target labels\n",
    "- Enables time-series splits\n",
    "- Provides consistent train/test data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and labels for feature view\n",
    "# Exclude: date (not a feature), qqq_close (raw price), targets (labels)\n",
    "feature_names = [col for col in features_clean.columns \n",
    "                 if col not in ['date', 'qqq_close', 'target_return', 'target_direction']]\n",
    "\n",
    "print(f\"\\nFeature View configuration:\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  Labels: target_return (regression), target_direction (classification)\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, feat in enumerate(feature_names, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query for feature view\n",
    "query = combined_fg.select(feature_names + ['target_return', 'target_direction'])\n",
    "\n",
    "# Create or get feature view\n",
    "print(\"\\nCreating feature view...\")\n",
    "\n",
    "try:\n",
    "    # Try to get existing feature view\n",
    "    feature_view = fs.get_feature_view(name='qqq_prediction_fv', version=1)\n",
    "    print(\"✓ Feature view already exists: qqq_prediction_fv (version 1)\")\n",
    "except:\n",
    "    # Create new feature view\n",
    "    feature_view = fs.create_feature_view(\n",
    "        name='qqq_prediction_fv',\n",
    "        version=1,\n",
    "        query=query,\n",
    "        labels=['target_return', 'target_direction']\n",
    "    )\n",
    "    print(\"✓ Created new feature view: qqq_prediction_fv (version 1)\")\n",
    "\n",
    "print(f\"\\nFeature View Summary:\")\n",
    "print(f\"  Name: {feature_view.name}\")\n",
    "print(f\"  Version: {feature_view.version}\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  Labels: {len(feature_view.labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**✅ Feature View created successfully**:\n",
    "\n",
    "**Feature Groups Joined**:\n",
    "- `qqq_technical_features`: Returns, volatility, RSI, MA ratios\n",
    "- `xlk_sector_features`: Sector returns and correlation\n",
    "- `vix_volatility_features`: Volatility regime indicators\n",
    "- `macro_features`: DGS10 and CPI (point-in-time correct)\n",
    "- `sentiment_features`: News sentiment (optional)\n",
    "\n",
    "**Targets Created**:\n",
    "- `target_return`: Next-day percentage return (regression)\n",
    "- `target_direction`: Binary up/down (classification)\n",
    "\n",
    "**Data Quality**:\n",
    "- All missing values handled (sentiment filled with 0, rolling window NaN dropped)\n",
    "- No look-ahead bias (targets use only future data, last row dropped)\n",
    "- Time-aligned features (all joined on date)\n",
    "\n",
    "**Hopsworks Assets Created**:\n",
    "- Feature Group: `qqq_combined_features`\n",
    "- Feature View: `qqq_prediction_fv` (version 1)\n",
    "\n",
    "**Next steps**:\n",
    "- Notebook 7: Train XGBoost models using time-series splits\n",
    "- Use Feature View for consistent train/test data access\n",
    "- Implement proper backtesting with purge gaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
