{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Backfill News Data with FinBERT Sentiment (Aggregated)\n",
    "\n",
    "Fetch historical news articles, apply FinBERT sentiment analysis, and aggregate to **daily sentiment metrics**.\n",
    "\n",
    "**Key Change**: We aggregate sentiment to daily metrics (no text columns) to avoid Hopsworks free tier limitations.\n",
    "\n",
    "**Pipeline**: NewsAPI → FinBERT → Daily Aggregation → Hopsworks FG\n",
    "\n",
    "**Features Created**:\n",
    "- `sentiment_mean`: Average daily compound sentiment\n",
    "- `sentiment_std`: Standard deviation of daily sentiment\n",
    "- `article_count`: Number of articles per day\n",
    "- `positive_mean`, `negative_mean`, `neutral_mean`: Average sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from utils.data_fetchers import fetch_news_articles, apply_finbert_sentiment\n",
    "from utils.feature_functions import aggregate_sentiment\n",
    "from utils.hopsworks_helpers import get_feature_store, create_feature_group\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load config\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FinBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT for financial sentiment analysis\n",
    "print(\"Loading FinBERT model...\")\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "print(\"✓ FinBERT model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch News Articles and Apply Sentiment Analysis\n",
    "\n",
    "**Note**: NewsAPI free tier has limits (100 requests/day). For full backfill:\n",
    "- Run this over multiple days, OR\n",
    "- Use a paid plan, OR\n",
    "- Sample specific dates\n",
    "\n",
    "**Fallback**: If NewsAPI key is invalid, you can use alternative sources like Finnhub or Alpha Vantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch last 30 days of news as demonstration\n",
    "# Adjust based on your NewsAPI plan and data needs\n",
    "\n",
    "end_date = datetime.strptime(config['data']['end_date'], '%Y-%m-%d')\n",
    "start_date = end_date - timedelta(days=29)  # Last 30 days\n",
    "\n",
    "query = config['data']['news']['query']\n",
    "all_articles = []\n",
    "\n",
    "print(f\"Fetching news from {start_date.date()} to {end_date.date()}...\")\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    date_str = current_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        articles = fetch_news_articles(query, date_str, max_articles=100)\n",
    "        \n",
    "        if articles:\n",
    "            print(f\"{date_str}: {len(articles)} articles\")\n",
    "            \n",
    "            for article in articles:\n",
    "                # Combine title and description for sentiment analysis\n",
    "                text = f\"{article.get('title', '')} {article.get('description', '')}\"\n",
    "                \n",
    "                # Skip if no text\n",
    "                if not text.strip():\n",
    "                    continue\n",
    "                \n",
    "                # Apply FinBERT\n",
    "                sentiment = apply_finbert_sentiment(text, model, tokenizer)\n",
    "                \n",
    "                all_articles.append({\n",
    "                    'date': date_str,\n",
    "                    **sentiment  # compound, positive, negative, neutral\n",
    "                })\n",
    "        \n",
    "        # Respect API rate limits\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        # Check if API key is invalid\n",
    "        if 'apiKeyInvalid' in error_msg or 'API key' in error_msg:\n",
    "            print(f\"\\n❌ ERROR: Invalid NewsAPI key\")\n",
    "            print(f\"\\nTo fix this:\")\n",
    "            print(f\"1. Get a free API key from https://newsapi.org/register\")\n",
    "            print(f\"2. Update NEWS_API_KEY in your .env file\")\n",
    "            print(f\"3. Re-run this notebook\\n\")\n",
    "            print(f\"\\nAlternatively, you can use Finnhub (free tier):\")\n",
    "            print(f\"1. Get API key from https://finnhub.io/register\")\n",
    "            print(f\"2. Modify fetch_news_articles() to use Finnhub instead\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"{date_str}: Error - {error_msg}\")\n",
    "    \n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Create DataFrame with article-level sentiment\n",
    "articles_df = pd.DataFrame(all_articles)\n",
    "print(f\"\\n✓ Total articles fetched: {len(articles_df)}\")\n",
    "\n",
    "if len(articles_df) > 0:\n",
    "    print(f\"  Date range: {articles_df['date'].min()} to {articles_df['date'].max()}\")\n",
    "    print(f\"\\nSample article-level sentiment:\")\n",
    "    print(articles_df.head())\n",
    "else:\n",
    "    print(\"\\n⚠️  No articles fetched. Check your API key or try alternative data source.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Load Sample News Data (if NewsAPI fails)\n",
    "\n",
    "If you don't have a valid NewsAPI key, you can:\n",
    "1. Use the sample data below for testing\n",
    "2. Manually create a CSV with article-level sentiment\n",
    "3. Use alternative news APIs (Finnhub, Alpha Vantage)\n",
    "\n",
    "**Uncomment the cell below to use sample data for testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE THIS IF NEWSAPI FAILED ABOVE\n",
    "# This creates sample sentiment data for testing the pipeline\n",
    "\n",
    "# import numpy as np\n",
    "# \n",
    "# # Generate sample news sentiment data (30 days, random articles per day)\n",
    "# sample_data = []\n",
    "# \n",
    "# for i in range(30):\n",
    "#     date = (end_date - timedelta(days=29-i)).strftime('%Y-%m-%d')\n",
    "#     num_articles = np.random.randint(5, 20)  # 5-20 articles per day\n",
    "#     \n",
    "#     for _ in range(num_articles):\n",
    "#         # Random sentiment scores (simulating FinBERT output)\n",
    "#         negative = np.random.beta(2, 5)  # Skewed toward lower values\n",
    "#         positive = np.random.beta(2, 5)\n",
    "#         neutral = 1 - negative - positive\n",
    "#         compound = positive - negative\n",
    "#         \n",
    "#         sample_data.append({\n",
    "#             'date': date,\n",
    "#             'negative': negative,\n",
    "#             'neutral': neutral,\n",
    "#             'positive': positive,\n",
    "#             'compound': compound\n",
    "#         })\n",
    "# \n",
    "# articles_df = pd.DataFrame(sample_data)\n",
    "# print(f\"✓ Generated {len(articles_df)} sample articles for testing\")\n",
    "# print(f\"  Date range: {articles_df['date'].min()} to {articles_df['date'].max()}\")\n",
    "# print(articles_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate to Daily Sentiment Metrics\n",
    "\n",
    "**Critical Step**: Aggregate article-level sentiment to daily metrics with ONLY numeric columns.\n",
    "\n",
    "This avoids Hopsworks free tier text column limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(articles_df) > 0:\n",
    "    print(\"Aggregating article-level sentiment to daily metrics...\\n\")\n",
    "    \n",
    "    # Use aggregate_sentiment function from feature_functions.py\n",
    "    daily_sentiment = aggregate_sentiment(articles_df, date_col='date')\n",
    "    \n",
    "    print(f\"✓ Daily sentiment features created\")\n",
    "    print(f\"  Shape: {daily_sentiment.shape}\")\n",
    "    print(f\"  Columns: {daily_sentiment.columns.tolist()}\")\n",
    "    print(f\"\\nSample daily sentiment:\")\n",
    "    print(daily_sentiment.head(10))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nDaily Sentiment Statistics:\")\n",
    "    print(daily_sentiment[['sentiment_mean', 'sentiment_std', 'article_count']].describe())\n",
    "else:\n",
    "    print(\"⚠️  Skipping aggregation - no article data available\")\n",
    "    daily_sentiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Daily Sentiment Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if daily_sentiment is not None and len(daily_sentiment) > 0:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Convert date to datetime for plotting\n",
    "    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "    \n",
    "    # 1. Sentiment mean over time\n",
    "    axes[0].plot(daily_sentiment['date'], daily_sentiment['sentiment_mean'], marker='o')\n",
    "    axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_title('Daily Average Sentiment (Compound Score)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Sentiment Mean')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Article count per day\n",
    "    axes[1].bar(daily_sentiment['date'], daily_sentiment['article_count'], alpha=0.7)\n",
    "    axes[1].set_title('Number of Articles per Day', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Article Count')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Sentiment distribution (positive/negative/neutral)\n",
    "    axes[2].plot(daily_sentiment['date'], daily_sentiment['positive_mean'], label='Positive', marker='o')\n",
    "    axes[2].plot(daily_sentiment['date'], daily_sentiment['negative_mean'], label='Negative', marker='o')\n",
    "    axes[2].plot(daily_sentiment['date'], daily_sentiment['neutral_mean'], label='Neutral', marker='o')\n",
    "    axes[2].set_title('Daily Sentiment Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Average Score')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Sentiment trends visualized\")\n",
    "else:\n",
    "    print(\"⚠️  Skipping visualization - no sentiment data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Daily Sentiment Features to Hopsworks\n",
    "\n",
    "**Key**: Upload ONLY the aggregated daily metrics (numeric columns), no text columns.\n",
    "\n",
    "This avoids the \"loadbalancer_external_domain_datanode not found\" error in Hopsworks free tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if daily_sentiment is not None and len(daily_sentiment) > 0:\n",
    "    print(\"Uploading daily sentiment features to Hopsworks...\\n\")\n",
    "    \n",
    "    # Connect to Hopsworks\n",
    "    fs = get_feature_store()\n",
    "    \n",
    "    # Ensure date is in correct format\n",
    "    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "    \n",
    "    # Verify all columns are numeric (except date)\n",
    "    print(\"Feature group schema:\")\n",
    "    print(daily_sentiment.dtypes)\n",
    "    print()\n",
    "    \n",
    "    # Create feature group with daily sentiment metrics\n",
    "    sentiment_fg = create_feature_group(\n",
    "        fs,\n",
    "        name='sentiment_features',\n",
    "        df=daily_sentiment,\n",
    "        primary_key=['date'],\n",
    "        description='Daily aggregated news sentiment from NewsAPI + FinBERT (no text columns)'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Sentiment features uploaded to Hopsworks!\")\n",
    "    print(f\"  Feature group: sentiment_features (version {sentiment_fg.version})\")\n",
    "    print(f\"  Features: {len(daily_sentiment.columns) - 1}\")  # -1 for date column\n",
    "    print(f\"  Samples: {len(daily_sentiment)}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Skipping Hopsworks upload - no sentiment data available\")\n",
    "    print(\"\\nTo complete this step:\")\n",
    "    print(\"1. Get a valid NewsAPI key from https://newsapi.org/register\")\n",
    "    print(\"2. Update NEWS_API_KEY in your .env file\")\n",
    "    print(\"3. Re-run this notebook\")\n",
    "    print(\"\\nOr use alternative news source (Finnhub, Alpha Vantage, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**✅ Daily sentiment features created (if news data available)**:\n",
    "\n",
    "**Feature Group**: `sentiment_features`\n",
    "- `sentiment_mean`: Average daily compound sentiment (-1 to +1)\n",
    "- `sentiment_std`: Sentiment volatility (dispersion)\n",
    "- `article_count`: Number of articles analyzed\n",
    "- `positive_mean`: Average positive score\n",
    "- `negative_mean`: Average negative score\n",
    "- `neutral_mean`: Average neutral score\n",
    "\n",
    "**Key Design Decisions**:\n",
    "1. **No text columns**: Only numeric features to avoid Hopsworks free tier limitations\n",
    "2. **Daily aggregation**: Article-level data aggregated to daily metrics\n",
    "3. **FinBERT**: Financial-domain sentiment model for accurate market sentiment\n",
    "4. **Missing days**: Days with no news will not appear (can be filled with 0 during feature view creation)\n",
    "\n",
    "**Next steps**:\n",
    "- Notebook 4: Create market features (QQQ technical, XLK sector, VIX volatility)\n",
    "- Notebook 5: Create macro features (DGS10, CPI)\n",
    "- Notebook 6: Join all features into feature view\n",
    "- Notebook 7: Train models\n",
    "\n",
    "**Note**: If you don't have a valid NewsAPI key, you can skip this notebook and proceed without sentiment features. The model will still work with market and macro features only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
